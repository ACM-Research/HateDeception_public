{"cells":[{"cell_type":"code","source":"import torch\nfrom copy import deepcopy","metadata":{"cell_id":"0180eadac0f24c6b95754ad0e1a25487","source_hash":"ccef545","execution_start":1680995332320,"execution_millis":2561,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/shared-libs/python3.9/py/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from textattack.datasets import HuggingFaceDataset\nfrom textattack.models.wrappers import HuggingFaceModelWrapper\nfrom textattack.models.wrappers import ModelWrapper\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer","metadata":{"cell_id":"bb930012822a448a85f48c6c431f967f","source_hash":"937c11a5","execution_start":1680995334913,"execution_millis":23660,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"2023-04-08 23:08:55.698824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2023-04-08 23:08:56.469042: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n2023-04-08 23:08:56.479733: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n2023-04-08 23:08:56.479755: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2023-04-08 23:08:56.583972: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2023-04-08 23:09:00.964098: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n2023-04-08 23:09:00.964212: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n2023-04-08 23:09:00.964221: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n2023-04-08 23:09:14.065536: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n2023-04-08 23:09:14.065585: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n2023-04-08 23:09:14.065608: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (p-e803e9f0-f341-4e63-9e5c-ecfa91ec1687): /proc/driver/nvidia/version does not exist\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip3 install captum","metadata":{"cell_id":"ce93c8df423d4a30bdd8639f5f262465","source_hash":"a0caf213","execution_start":1680995358593,"execution_millis":13587,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Requirement already satisfied: captum in /root/venv/lib/python3.9/site-packages (0.6.0)\nRequirement already satisfied: matplotlib in /shared-libs/python3.9/py/lib/python3.9/site-packages (from captum) (3.6.0)\nRequirement already satisfied: torch>=1.6 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from captum) (1.12.1)\nRequirement already satisfied: numpy in /shared-libs/python3.9/py/lib/python3.9/site-packages (from captum) (1.23.4)\nRequirement already satisfied: typing-extensions in /shared-libs/python3.9/py/lib/python3.9/site-packages (from torch>=1.6->captum) (4.4.0)\nRequirement already satisfied: cycler>=0.10 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->captum) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->captum) (9.2.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->captum) (1.4.4)\nRequirement already satisfied: pyparsing>=2.2.1 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->captum) (3.0.9)\nRequirement already satisfied: packaging>=20.0 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->captum) (21.3)\nRequirement already satisfied: contourpy>=1.0.1 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->captum) (1.0.5)\nRequirement already satisfied: python-dateutil>=2.7 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from matplotlib->captum) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /shared-libs/python3.9/py/lib/python3.9/site-packages (from matplotlib->captum) (4.37.4)\nRequirement already satisfied: six>=1.5 in /shared-libs/python3.9/py-core/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n\u001b[33mWARNING: You are using pip version 22.0.4; however, version 23.0.1 is available.\nYou should consider upgrading via the '/root/venv/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n\u001b[0m^C\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from captum.attr import IntegratedGradients, LayerConductance, LayerIntegratedGradients, LayerDeepLiftShap, InternalInfluence, LayerGradientXActivation\nfrom captum.attr import visualization as viz","metadata":{"cell_id":"a5af94b9dab6447ba937fe6bbf3541db","source_hash":"35eb0726","execution_start":1680995372187,"execution_millis":101,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")\nelse:\n    device = torch.device(\"cpu\")\n\nprint(device)","metadata":{"cell_id":"a62a50b16ea3486bb7b8016300a9c97e","source_hash":"43e3cdab","execution_start":1680995372298,"execution_millis":70,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"dataset = HuggingFaceDataset(\"ag_news\", None, \"train\")\noriginal_model = AutoModelForSequenceClassification.from_pretrained(\"textattack/bert-base-uncased-ag-news\")\noriginal_tokenizer = AutoTokenizer.from_pretrained(\"textattack/bert-base-uncased-ag-news\")\nmodel = HuggingFaceModelWrapper(original_model,original_tokenizer)","metadata":{"cell_id":"3e38f5c78d5c46918cf2c0c62c10666c","source_hash":"5efa1384","execution_start":1680995372410,"execution_millis":34861,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"Downloading builder script: 4.06kB [00:00, 3.24MB/s]                   \nDownloading metadata: 2.65kB [00:00, 682kB/s]                    \nUsing custom data configuration default\nDownloading and preparing dataset ag_news/default (download: 29.88 MiB, generated: 30.23 MiB, post-processed: Unknown size, total: 60.10 MiB) to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548...\nDownloading data: 29.5MB [00:01, 20.1MB/s]\nDownloading data: 1.86MB [00:00, 19.3MB/s]                  \nDataset ag_news downloaded and prepared to /root/.cache/huggingface/datasets/ag_news/default/0.0.0/bc2bcb40336ace1a0374767fc29bb0296cdaf8a6da7298436239c54d79180548. Subsequent calls will reuse this data.\n100%|██████████| 2/2 [00:00<00:00, 599.96it/s]\ntextattack: Loading \u001b[94mdatasets\u001b[0m dataset \u001b[94mag_news\u001b[0m, split \u001b[94mtrain\u001b[0m.\nDownloading (…)lve/main/config.json: 100%|██████████| 706/706 [00:00<00:00, 91.3kB/s]\nDownloading pytorch_model.bin: 100%|██████████| 438M/438M [00:03<00:00, 125MB/s]\nDownloading (…)okenizer_config.json: 100%|██████████| 48.0/48.0 [00:00<00:00, 18.4kB/s]\nDownloading (…)solve/main/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 54.2MB/s]\nDownloading (…)cial_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 43.9kB/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def get_text(tokenizer,input_ids,token_type_ids,attention_mask):\n    list_of_text = []\n    number = input_ids.size()[0]\n    for i in range(number):\n        ii = input_ids[i,].cpu().numpy()\n        tt = token_type_ids[i,]\n        am = attention_mask[i,]\n        txt = tokenizer.decode(ii, skip_special_tokens=True)\n        list_of_text.append(txt)\n    return list_of_text\n\nsel =2\nbatch_encoded = model.tokenizer([dataset[i][0]['text'] for i in range(sel)], padding=True, return_tensors=\"pt\")\nbatch_encoded.to(device)\nlabels = [dataset[i][1] for i in range(sel)]\n\nclone = deepcopy(model)\nclone.model.to(device)\n\ndef calculate(input_ids,token_type_ids,attention_mask):\n    #convert back to list of text\n    return clone.model(input_ids,token_type_ids,attention_mask)[0]\n\n# x = calculate(**batch_encoded)\n\nlig = LayerIntegratedGradients(calculate, clone.model.bert.embeddings)\n# lig = InternalInfluence(calculate, clone.model.bert.embeddings)\n# lig = LayerGradientXActivation(calculate, clone.model.bert.embeddings)\n\nbsl = torch.zeros(batch_encoded['input_ids'].size()).type(torch.LongTensor).to(device)\nlabels = torch.tensor(labels).to(device)\n\nattributions,delta = lig.attribute(inputs=batch_encoded['input_ids'],\n                              baselines=bsl,\n                              additional_forward_args=(batch_encoded['token_type_ids'], batch_encoded['attention_mask']),\n                              n_steps = 10,\n                              target = labels,\n                              return_convergence_delta=True\n                              )\natts = attributions.sum(dim=-1).squeeze(0)\natts = atts / torch.norm(atts)","metadata":{"cell_id":"d90eab54e4ac48ed8079ee1c8c070136","source_hash":"23e5fcbe","execution_start":1680995407282,"execution_millis":41613,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":7},{"cell_type":"code","source":"atts = attributions.sum(dim=-1).squeeze(0)\natts = atts / torch.norm(atts)","metadata":{"cell_id":"5c0ed38591f64c56aced30c5a777e850","source_hash":"ba9bac45","execution_start":1680995448898,"execution_millis":71,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from textattack.attack_recipes import PWWSRen2019\nattack = PWWSRen2019.build(model)","metadata":{"cell_id":"82c66dedb60646c881aa8715725c0db3","source_hash":"18bbfc0","execution_start":1680995448988,"execution_millis":6480,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\ntextattack: Unknown if model of class <class 'transformers.models.bert.modeling_bert.BertForSequenceClassification'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from textattack import Attacker\n\nattacker = Attacker(attack, dataset)\nattacker.attack_dataset()","metadata":{"cell_id":"ce41fb51c23f46f69e7d47984e80242c","source_hash":"f174d7e9","execution_start":1680995455478,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Attack(\n  (search_method): GreedyWordSwapWIR(\n    (wir_method):  weighted-saliency\n  )\n  (goal_function):  UntargetedClassification\n  (transformation):  WordSwapWordNet\n  (constraints): \n    (0): RepeatModification\n    (1): StopwordModification\n  (is_black_box):  True\n) \n\n  0%|          | 0/10 [00:00<?, ?it/s]","output_type":"stream"},{"output_type":"error","ename":"KernelInterrupted","evalue":"Execution interrupted by the Jupyter kernel.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKernelInterrupted\u001b[0m: Execution interrupted by the Jupyter kernel."]}],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e803e9f0-f341-4e63-9e5c-ecfa91ec1687' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"96e0d7ecdaf1430187be59b743670782","deepnote_execution_queue":[]}}