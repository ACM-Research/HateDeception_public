# DisinfoDeception_public

Using Adversarial Attacks to Deceive Political Disinformation Models on Twitter

Overview and timeline:
https://docs.google.com/document/d/1PrVKPqJqnmbhMPXLQA3_EGEC46qQAEQWb3ejo9TvvRo/edit#

## Description

You will attempt to fool machine learning models trained to detect political disinformation on Twitter using adversarial learning. An adversarial attack feeds a model seemingly normal input data (adversarial examples) which is actually designed to deceive the model into outputting an intended mistake. You will become involved with training the imitation (victim) and attacker models, data scraping additional training datasets from Twitter posts, generating adversarial examples, and testing the deception attacks. This project aims to identify if political actors can bypass detection systems using adversarial learning to spread misinformation to fool public understanding of social media.
